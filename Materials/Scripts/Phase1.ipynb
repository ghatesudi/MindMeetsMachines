{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d129e3-863c-4d1d-991b-925c0994e878",
   "metadata": {},
   "source": [
    "# Minds Meet Machines (MMM) Challenge ‚Äî Phase 1: Pre-Adjudication Analysis\n",
    "\n",
    "**Date:** 09/10/2025  \n",
    "**OMOP Vocabulary Version:** August 27, 2025# Execution environment & requirements\n",
    "\n",
    "**Python**: 3.9+ recommended.  \n",
    "**Main packages**: pandas, numpy, matplotlib, seaborn, upsetplot, scikit-learn, nbformat.\n",
    "\n",
    "Example (pip):\n",
    "\n",
    "\n",
    "**Abstract:**  \n",
    "This notebook performs Phase 1 (pre-adjudication) analyses for the MMM challenge. It compares concept sets generated by human and GenAI workflows, quantifies agreement using Jaccard similarity and other metrics, and produces visual summaries for downstream adjudication and consensus processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b97fb-9170-4710-8a4c-22570b7c74d2",
   "metadata": {},
   "source": [
    "# Execution environment & requirements\n",
    "\n",
    "**Python**: 3.9+ recommended.  \n",
    "**Main packages**: pandas, numpy, matplotlib, seaborn, upsetplot, scikit-learn, nbformat.\n",
    "\n",
    "Example (pip):\n",
    "pip install pandas numpy matplotlib seaborn upsetplot scikit-learn nbformat\n",
    "\n",
    "If you use conda, create an environment and install equivalents. For exact reproducibility, include a `requirements.txt` or `environment.yml` in the repo root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45046311-5be6-4a10-b9b8-f77aee03dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Import required libraries\n",
    "# ------------------------------\n",
    "\n",
    "# OS and file handling\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For generating combinations and permutations\n",
    "from itertools import combinations\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Random utilities (if needed later)\n",
    "import random\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c3895-cc2b-4c3b-82bc-53bb700c1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Phase 1 ‚Äî Subgroup analysis (Split & Reconciliation)\n",
    "# Run this BEFORE Gold Standard (TGS) generation\n",
    "# -----------------------------\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------------------------\n",
    "# Robust ROOT_DIR setup (auto-detect)\n",
    "# --------------------------------------------\n",
    "try:\n",
    "    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    SCRIPT_DIR = os.getcwd()\n",
    "\n",
    "# Try ../ConceptSets relative to script\n",
    "ROOT_DIR = os.path.abspath(os.path.join(SCRIPT_DIR, '..', 'ConceptSets'))\n",
    "\n",
    "# If not found, fallback to sibling directory ConceptSets\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    alt_root = os.path.join(SCRIPT_DIR, 'ConceptSets')\n",
    "    if os.path.exists(alt_root):\n",
    "        ROOT_DIR = os.path.abspath(alt_root)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è ConceptSets folder not found relative to script.\")\n",
    "        ROOT_DIR = None\n",
    "\n",
    "# print(f\"\\nSCRIPT_DIR: {SCRIPT_DIR}\")\n",
    "# print(f\"Current working directory: {os.getcwd()}\")\n",
    "# print(f\"ROOT_DIR (resolved): {ROOT_DIR}\")\n",
    "\n",
    "# Verify folder contents\n",
    "if ROOT_DIR and os.path.exists(ROOT_DIR):\n",
    "    folders = [f for f in os.listdir(ROOT_DIR) if os.path.isdir(os.path.join(ROOT_DIR, f))]\n",
    "    # print(f\"üß© Found {len(folders)} folders in ConceptSets: {folders[:10]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ROOT_DIR invalid or empty.\")\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Output and constants\n",
    "# --------------------------------------------\n",
    "OUT_DIR_PHASE1 = os.path.join(SCRIPT_DIR, 'results', 'phase1_subgroup_analysis')\n",
    "os.makedirs(OUT_DIR_PHASE1, exist_ok=True)\n",
    "\n",
    "CONCEPT_COUNTS_FILE = \"ConceptRecordCounts.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Helper functions\n",
    "# -------------------------\n",
    "def strip_numeric_prefix(name):\n",
    "    \"\"\"Remove leading digits, dashes, or underscores like '0152-'.\"\"\"\n",
    "    return re.sub(r\"^[\\d\\-\\_]+\", \"\", name).strip()\n",
    "\n",
    "def clean_arm_name(folder_name):\n",
    "    name = folder_name.strip()\n",
    "    match = re.search(r\"\\[(AI\\d+|H\\d+|Human|Reviewer|Clinician|Manual|Expert)\\]\", name, re.IGNORECASE)\n",
    "    if match:\n",
    "        arm = match.group(1).upper()\n",
    "        if arm.startswith(\"H\"):\n",
    "            arm = \"HUMAN\"\n",
    "        return arm\n",
    "    return name.upper()\n",
    "\n",
    "def is_subgroup(folder_name):\n",
    "    name = strip_numeric_prefix(folder_name)\n",
    "    return bool(re.search(r\"\\[H\\d+\\].*\\[S\\d+\\]\", name, re.IGNORECASE))\n",
    "\n",
    "def is_final_human(folder_name):\n",
    "    name = strip_numeric_prefix(folder_name)\n",
    "    return bool(re.search(r\"\\[H\\d+\\](?!.*\\[S\\d+\\])\", name, re.IGNORECASE))\n",
    "\n",
    "def is_ai(folder_name):\n",
    "    name = strip_numeric_prefix(folder_name)\n",
    "    return bool(re.search(r\"\\[AI\\d+\\]\", name, re.IGNORECASE))\n",
    "\n",
    "def load_included_concepts(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "    except Exception as e:\n",
    "        print(f\"[load_included_concepts] Error reading {file_path}: {e}\")\n",
    "        return set()\n",
    "    cols = [c.strip() for c in df.columns]\n",
    "    norm_map = {re.sub(r'[^a-z0-9]', '', c.lower()): c for c in cols}\n",
    "    chosen = None\n",
    "    if 'conceptid' in norm_map:\n",
    "        chosen = norm_map['conceptid']\n",
    "    else:\n",
    "        for norm, orig in norm_map.items():\n",
    "            if 'concept' in norm and 'id' in norm and 'set' not in norm:\n",
    "                chosen = orig\n",
    "                break\n",
    "    if not chosen:\n",
    "        for c in cols:\n",
    "            if df[c].dropna().astype(str).str.match(r'^\\d+$').any():\n",
    "                chosen = c\n",
    "                break\n",
    "    if not chosen:\n",
    "        return set()\n",
    "    vals = df[chosen].dropna().astype(str).str.strip().str.replace(r'\\.0+$', '', regex=True)\n",
    "    return set(vals[vals != ''].tolist())\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Load record counts (for weighting)\n",
    "# --------------------------------------------\n",
    "if os.path.exists(CONCEPT_COUNTS_FILE):\n",
    "    rc_df = pd.read_csv(CONCEPT_COUNTS_FILE, dtype=str)\n",
    "    if 'conceptId' in rc_df.columns and 'record_count' in rc_df.columns:\n",
    "        rc_df['record_count'] = rc_df['record_count'].astype(float)\n",
    "        record_map = dict(zip(rc_df['conceptId'].astype(str), rc_df['record_count'].astype(float)))\n",
    "    else:\n",
    "        record_map = {}\n",
    "else:\n",
    "    record_map = {}\n",
    "    print(f\"‚ö†Ô∏è {CONCEPT_COUNTS_FILE} not found; weighted metrics will use 0 weights.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Metric helpers\n",
    "# -------------------------\n",
    "def weighted_PRF(arm_set, ref_set):\n",
    "    tp = set(arm_set) & set(ref_set)\n",
    "    fp = set(arm_set) - set(ref_set)\n",
    "    fn = set(ref_set) - set(arm_set)\n",
    "    WTP = sum(record_map.get(str(c), 0.0) for c in tp)\n",
    "    WFP = sum(record_map.get(str(c), 0.0) for c in fp)\n",
    "    WFN = sum(record_map.get(str(c), 0.0) for c in fn)\n",
    "    P = WTP / (WTP + WFP) if (WTP + WFP) else np.nan\n",
    "    R = WTP / (WTP + WFN) if (WTP + WFN) else np.nan\n",
    "    F1 = (2 * P * R / (P + R)) if (P and R and (P + R)) else np.nan\n",
    "    return P, R, F1\n",
    "\n",
    "def unweighted_PRF(arm_set, ref_set):\n",
    "    tp = set(arm_set) & set(ref_set)\n",
    "    fp = set(arm_set) - set(ref_set)\n",
    "    fn = set(ref_set) - set(arm_set)\n",
    "    P = len(tp) / (len(tp) + len(fp)) if (len(tp) + len(fp)) else np.nan\n",
    "    R = len(tp) / (len(tp) + len(fn)) if (len(tp) + len(fn)) else np.nan\n",
    "    F1 = (2 * P * R / (P + R)) if (P and R and (P + R)) else np.nan\n",
    "    return P, R, F1\n",
    "\n",
    "def pairwise_f1_matrix(sets_dict, weighted=True):\n",
    "    names = list(sets_dict.keys())\n",
    "    mat = pd.DataFrame(index=names, columns=names, dtype=float)\n",
    "    for i, a in enumerate(names):\n",
    "        for j, b in enumerate(names):\n",
    "            if i <= j:\n",
    "                if weighted:\n",
    "                    _, _, f = weighted_PRF(sets_dict[a], sets_dict[b])\n",
    "                else:\n",
    "                    _, _, f = unweighted_PRF(sets_dict[a], sets_dict[b])\n",
    "                mat.loc[a, b] = f\n",
    "                mat.loc[b, a] = f\n",
    "    return mat\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Identify disease folders (robustly)\n",
    "# -------------------------\n",
    "# ‚úÖ Restrict to these diseases only\n",
    "TARGET_DISEASES = {\n",
    "    'C01': 'SLE',\n",
    "    'C02': 'RheumatoidArthritis',\n",
    "    'C03': 'DiabetesMacularEdema',\n",
    "    'C04': 'DeepVeinThrombosis',\n",
    "    'C06': 'Uveitis',\n",
    "    'C07': 'SystemicSclerosis'\n",
    "}\n",
    "\n",
    "raw_folders = [f for f in os.listdir(ROOT_DIR) if os.path.isdir(os.path.join(ROOT_DIR, f))]\n",
    "\n",
    "# Remove leading numbers and dashes like '0152-'\n",
    "cleaned_folders = [strip_numeric_prefix(f) for f in raw_folders]\n",
    "\n",
    "# ‚úÖ Keep only valid concept set arms:\n",
    "# - Must have a [C##] pattern\n",
    "# - Must NOT contain \"ONLINE\" (case-insensitive)\n",
    "disease_folders = [\n",
    "    f for f in cleaned_folders\n",
    "    if re.search(r'\\[C\\d+\\]', f, re.IGNORECASE)\n",
    "    and not re.search(r'ONLINE', f, re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# print(f\"\\nüß© Found {len(disease_folders)} disease-arm folders (filtered for non-ONLINE):\")\n",
    "# print(\"  Examples:\", disease_folders[:10])\n",
    "\n",
    "# ‚úÖ Group folders by disease code (C01, C02, etc.)\n",
    "from collections import defaultdict\n",
    "disease_groups = defaultdict(list)\n",
    "\n",
    "for raw, clean in zip(raw_folders, cleaned_folders):\n",
    "    # skip ONLINE folders entirely\n",
    "    if re.search(r'ONLINE', clean, re.IGNORECASE):\n",
    "        continue\n",
    "    m = re.search(r'\\[(C\\d+)\\]', clean, re.IGNORECASE)\n",
    "    if m:\n",
    "        disease_code = m.group(1).upper()\n",
    "        # Only include if it's part of TARGET_DISEASES\n",
    "        if disease_code in TARGET_DISEASES:\n",
    "            disease_groups[disease_code].append(raw)\n",
    "\n",
    "# Diagnostic output\n",
    "# print(f\"\\nüß¨ Grouped into {len(disease_groups)} target disease codes:\")\n",
    "# for k, v in sorted(disease_groups.items()):\n",
    "#     print(f\"  {k} ({TARGET_DISEASES[k]}): {len(v)} folders ‚Üí {v[:3]}\")\n",
    "\n",
    "# If no matching folders found, warn early\n",
    "if not disease_groups:\n",
    "    print(\"‚ö†Ô∏è No matching disease folders found for specified TARGET_DISEASES. Check folder names.\")\n",
    "\n",
    "# -------------------------\n",
    "# Iterate diseases and compute Phase 1 stats\n",
    "# -------------------------\n",
    "phase1_summaries = []\n",
    "\n",
    "for disease_code, disease_folders in sorted(disease_groups.items()):\n",
    "    # print(f\"\\nüîç === Processing {disease_code} ===\")\n",
    "    disease_dir = ROOT_DIR\n",
    "    subfolders = disease_folders\n",
    "    # print(f\"  Found {len(subfolders)} arms ‚Üí {subfolders[:5]}\")\n",
    "\n",
    "    # Classify arms\n",
    "    subteams = {}\n",
    "    final_human = None\n",
    "    ai_arms = {}\n",
    "    for s in subfolders:\n",
    "        csvp = os.path.join(disease_dir, s, 'includedConcepts.csv')\n",
    "        if not os.path.exists(csvp):\n",
    "            # print(f\"  ‚ö†Ô∏è Missing includedConcepts.csv in {s}\")\n",
    "            continue\n",
    "        if is_subgroup(s):\n",
    "            subteams[s] = load_included_concepts(csvp)\n",
    "        elif is_final_human(s):\n",
    "            final_human = (s, load_included_concepts(csvp))\n",
    "        elif is_ai(s):\n",
    "            ai_arms[s] = load_included_concepts(csvp)\n",
    "\n",
    "    # print(f\"  ‚Üí #subteams={len(subteams)} | #AI={len(ai_arms)} | FinalHuman={bool(final_human)}\")\n",
    "\n",
    "    if not subteams:\n",
    "        # print(f\"  ‚ö†Ô∏è No subteams detected for {disease_code}. Skipping.\")\n",
    "        continue\n",
    "    if final_human is None:\n",
    "        # print(f\"  ‚ö†Ô∏è No final human arm found for {disease_code}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Workflow sets\n",
    "    workflow_sets = {}\n",
    "    for k, sset in subteams.items():\n",
    "        workflow_sets[f\"SUB_{k}\"] = sset\n",
    "    if final_human:\n",
    "        workflow_sets[f\"FINAL_{final_human[0]}\"] = final_human[1]\n",
    "    for k, aset in ai_arms.items():\n",
    "        workflow_sets[f\"AI_{k}\"] = aset\n",
    "\n",
    "    # Compute metrics\n",
    "    sub_names = [n for n in workflow_sets.keys() if n.startswith('SUB_')]\n",
    "    pw_unweighted = pairwise_f1_matrix(workflow_sets, weighted=False)\n",
    "    pw_weighted = pairwise_f1_matrix(workflow_sets, weighted=True)\n",
    "\n",
    "    avg_pair_un = np.nan\n",
    "    avg_pair_w = np.nan\n",
    "    if len(sub_names) >= 2:\n",
    "        pair_vals_un = [pw_unweighted.loc[a, b] for a, b in itertools.combinations(sub_names, 2)]\n",
    "        pair_vals_w = [pw_weighted.loc[a, b] for a, b in itertools.combinations(sub_names, 2)]\n",
    "        avg_pair_un = np.nanmean(pair_vals_un)\n",
    "        avg_pair_w = np.nanmean(pair_vals_w)\n",
    "\n",
    "    final_name = next((n for n in workflow_sets.keys() if n.startswith('FINAL_')), None)\n",
    "    mean_final_vs_sub_un = np.nan\n",
    "    mean_final_vs_sub_w = np.nan\n",
    "    if final_name:\n",
    "        f_vs_sub_un = [pw_unweighted.loc[final_name, s] for s in sub_names]\n",
    "        f_vs_sub_w = [pw_weighted.loc[final_name, s] for s in sub_names]\n",
    "        mean_final_vs_sub_un = np.nanmean(f_vs_sub_un)\n",
    "        mean_final_vs_sub_w = np.nanmean(f_vs_sub_w)\n",
    "\n",
    "    consensus_gain_un = (mean_final_vs_sub_un - avg_pair_un) if not np.isnan(mean_final_vs_sub_un) else np.nan\n",
    "    consensus_gain_w = (mean_final_vs_sub_w - avg_pair_w) if not np.isnan(mean_final_vs_sub_w) else np.nan\n",
    "\n",
    "    # Save summary row\n",
    "    row = {\n",
    "        'Disease': disease_code,\n",
    "        'N_subteams': len(sub_names),\n",
    "        'N_ai_arms': sum(1 for n in workflow_sets if n.startswith('AI_')),\n",
    "        'Union_concepts': len(set().union(*workflow_sets.values())),\n",
    "        'Avg_pairwise_sub_unweighted': avg_pair_un,\n",
    "        'Avg_pairwise_sub_weighted': avg_pair_w,\n",
    "        'Mean_final_vs_sub_unweighted': mean_final_vs_sub_un,\n",
    "        'Mean_final_vs_sub_weighted': mean_final_vs_sub_w,\n",
    "        'Consensus_Gain_proxy_unweighted': consensus_gain_un,\n",
    "        'Consensus_Gain_proxy_weighted': consensus_gain_w\n",
    "    }\n",
    "    phase1_summaries.append(row)\n",
    "\n",
    "    # print(f\"  ‚úÖ Added summary row for {disease_code}\")\n",
    "\n",
    "# -------------------------\n",
    "# Save + verify\n",
    "# -------------------------\n",
    "phase1_df = pd.DataFrame(phase1_summaries)\n",
    "phase1_df.to_csv(os.path.join(OUT_DIR_PHASE1, \"phase1_summary_across_diseases.csv\"), index=False)\n",
    "# print(\"\\nüìä Saved Phase1 summary ‚Üí\", os.path.join(OUT_DIR_PHASE1, \"phase1_summary_across_diseases.csv\"))\n",
    "# print(\"Columns:\", phase1_df.columns.tolist())\n",
    "# print(\"Shape:\", phase1_df.shape)\n",
    "# print(phase1_df.head())\n",
    "\n",
    "if phase1_df.empty:\n",
    "    print(\"‚ö†Ô∏è phase1_df is EMPTY ‚Äî no valid subgroups or final human folders detected. Check folder naming pattern and includedConcepts.csv presence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a6c57a-dbb8-4320-9ff2-30e56a84292f",
   "metadata": {},
   "source": [
    "### Phase 1 ‚Äî Filtered Summary Table for Consensus Gain Analysis (FRD 6.2.2)\n",
    "- This cell filters the Phase 1 summary to retain only the most relevant metrics for assessing human and AI subgroup variability.\n",
    "- This table summarizes Phase 1 (Pre-Adjudication) human subgroup consistency and consensus improvement.\n",
    "It compares how similar individual human sub-teams were to each other and to the final reconciled human set, using Jaccard similarity (unweighted and prevalence-weighted).\n",
    "The Consensus Gain Proxy indicates how much agreement improved after reconciliation ‚Äî positive values reflect stronger post-reconciliation alignment.\n",
    "- The selected columns are:  \n",
    "  - **Disease:** Identifier for each clinical idea analyzed.  \n",
    "  - **N_subteams:** Number of independent human subgroups.  \n",
    "  - **N_ai_arms:** Number of AI workflows compared.  \n",
    "  - **Union_concepts:** Total unique concepts across all workflows.  \n",
    "  - **Unweighted Consensus Gain Proxy** ‚Üí Measures improvement in agreement treating all concepts equally, regardless of how common or rare they are in clinical data.\n",
    "‚Üí Reflects pure conceptual overlap among sub-teams.\n",
    "  - **Weighted Consensus Gain Proxy** ‚Üí Gives more weight to clinically frequent (high-prevalence) concepts using record counts.\n",
    "‚Üí Reflects agreement improvement driven by important or common concepts, not rare ones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acd79d-d161-479a-948c-136c7f2dc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(OUT_DIR_PHASE1, \"phase1_summary_across_diseases.csv\"))\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab9854-08c8-4df3-addd-edae505501d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    'Disease',\n",
    "    'N_subteams',\n",
    "    'N_ai_arms',\n",
    "    'Union_concepts',\n",
    "    'Consensus_Gain_proxy_unweighted',\n",
    "    'Consensus_Gain_proxy_weighted'\n",
    "]\n",
    "\n",
    "df_filtered = df[cols_to_keep]\n",
    "df_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cfe2b-4a0f-4724-84ba-f0bcb9d297b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Phase A ‚Äî Pre-Adjudication (AI vs Final Human)\n",
    "# Combines statistical rigor + transparent numeric reporting\n",
    "# ==========================================================\n",
    "\n",
    "import os, re, itertools, warnings\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Robust ROOT_DIR setup (auto-detect)\n",
    "# --------------------------------------------\n",
    "try:\n",
    "    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    SCRIPT_DIR = os.getcwd()\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(SCRIPT_DIR, '..', 'ConceptSets'))\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    alt_root = os.path.join(SCRIPT_DIR, 'ConceptSets')\n",
    "    if os.path.exists(alt_root):\n",
    "        ROOT_DIR = os.path.abspath(alt_root)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è ConceptSets folder not found.\")\n",
    "        ROOT_DIR = None\n",
    "\n",
    "OUT_DIR_PHASEA = os.path.join(SCRIPT_DIR, 'results', 'phaseA_pre_adjudication')\n",
    "os.makedirs(OUT_DIR_PHASEA, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Arm Detection Helpers\n",
    "# ----------------------------------------------------------\n",
    "def strip_numeric_prefix(name):\n",
    "    return re.sub(r\"^[\\d\\-\\_]+\", \"\", name).strip()\n",
    "\n",
    "def is_ai(name):\n",
    "    return bool(re.search(r\"\\[AI\\d+\\]\", name, re.IGNORECASE))\n",
    "\n",
    "def is_final_human(name):\n",
    "    return bool(re.search(r\"\\[H\\d+\\](?!.*\\[S\\d+\\])\", name, re.IGNORECASE))\n",
    "\n",
    "def clean_arm_name(folder_name):\n",
    "    \"\"\"Convert folder to readable arm label.\"\"\"\n",
    "    match = re.search(r\"\\[(AI\\d+|H\\d+)\\]\", folder_name, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return folder_name\n",
    "    arm = match.group(1).upper()\n",
    "    if arm.startswith(\"H\"):\n",
    "        arm = \"HUMAN\"\n",
    "    return arm\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load Concepts\n",
    "# ----------------------------------------------------------\n",
    "def load_included_concepts(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "    except Exception as e:\n",
    "        print(f\"[load_included_concepts] ‚ùå Error reading {file_path}: {e}\")\n",
    "        return set()\n",
    "\n",
    "    cols = [c.strip() for c in df.columns]\n",
    "    norm_map = {re.sub(r'[^a-z0-9]', '', c.lower()): c for c in cols}\n",
    "    chosen = None\n",
    "    if 'conceptid' in norm_map:\n",
    "        chosen = norm_map['conceptid']\n",
    "    else:\n",
    "        for norm, orig in norm_map.items():\n",
    "            if 'concept' in norm and 'id' in norm:\n",
    "                chosen = orig\n",
    "                break\n",
    "    if not chosen:\n",
    "        return set()\n",
    "\n",
    "    vals = df[chosen].dropna().astype(str).str.strip().str.replace(r'\\.0+$', '', regex=True)\n",
    "    return set(vals[vals != ''])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load record count metadata\n",
    "# ----------------------------------------------------------\n",
    "record_map = {}\n",
    "if os.path.exists(\"ConceptRecordCounts.csv\"):\n",
    "    rc = pd.read_csv(\"ConceptRecordCounts.csv\", dtype=str)\n",
    "    rc['record_count'] = rc['record_count'].astype(float)\n",
    "    record_map = dict(zip(rc['conceptId'].astype(str), rc['record_count']))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Similarity Function\n",
    "# ----------------------------------------------------------\n",
    "def jaccard_index(a, b):\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union else np.nan\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Disease Analysis\n",
    "# ----------------------------------------------------------\n",
    "def analyze_disease(disease_code, disease_name, folders):\n",
    "    \"\"\"Compare AI arms vs Final Human for one disease (flat structure).\"\"\"\n",
    "    arm_data = {}\n",
    "\n",
    "    # collect includedConcepts.csv for AI + Human\n",
    "    for f in folders:\n",
    "        if re.search(r'ONLINE', f, re.IGNORECASE):\n",
    "            continue  # skip online\n",
    "        subpath = os.path.join(ROOT_DIR, f, \"includedConcepts.csv\")\n",
    "        if not os.path.exists(subpath):\n",
    "            continue\n",
    "        if is_ai(f) or is_final_human(f):\n",
    "            arm_data[clean_arm_name(f)] = load_included_concepts(subpath)\n",
    "\n",
    "    if len(arm_data) < 2:\n",
    "        print(f\"‚ö†Ô∏è Skipping {disease_code}_{disease_name}: not enough valid arms (AI + Human).\")\n",
    "        return None\n",
    "\n",
    "    all_concepts = set().union(*arm_data.values())\n",
    "    shared_all = set.intersection(*arm_data.values()) if len(arm_data) > 1 else set()\n",
    "\n",
    "    print(f\"\\n=== Disease: {disease_code}_{disease_name} ===\")\n",
    "    print(f\"Arms: {list(arm_data.keys())}\")\n",
    "    print(f\"Total unique concepts: {len(all_concepts)}\")\n",
    "    print(f\"Concepts common to all arms: {len(shared_all)}\")\n",
    "\n",
    "    # Arm-level numeric summary\n",
    "    stats = []\n",
    "    for arm, concepts in arm_data.items():\n",
    "        others_union = set.union(*(v for k, v in arm_data.items() if k != arm))\n",
    "        stats.append({\n",
    "            'Disease': f\"{disease_code}_{disease_name}\",\n",
    "            'Arm': arm,\n",
    "            'Concepts_Total': len(concepts),\n",
    "            'Unique_to_Arm': len(concepts - others_union),\n",
    "            'Shared_with_All': len(concepts & shared_all)\n",
    "        })\n",
    "    summary_df = pd.DataFrame(stats)\n",
    "\n",
    "    # Pairwise Jaccard matrix\n",
    "    arms = list(arm_data.keys())\n",
    "    jmat = pd.DataFrame(np.nan, index=arms, columns=arms)\n",
    "    for a, b in itertools.combinations_with_replacement(arms, 2):\n",
    "        j = jaccard_index(arm_data[a], arm_data[b])\n",
    "        jmat.loc[a, b] = jmat.loc[b, a] = j\n",
    "    np.fill_diagonal(jmat.values, 1.0)\n",
    "\n",
    "    # Save results\n",
    "    disease_out = os.path.join(OUT_DIR_PHASEA, f\"{disease_code}_{disease_name}\")\n",
    "    os.makedirs(disease_out, exist_ok=True)\n",
    "    summary_df.to_csv(os.path.join(disease_out, \"arm_summary.csv\"), index=False)\n",
    "    jmat.to_csv(os.path.join(disease_out, \"jaccard_matrix.csv\"))\n",
    "\n",
    "    mean_ai_human = np.nan\n",
    "    if \"HUMAN\" in arms:\n",
    "        ai_arms = [a for a in arms if a.startswith(\"AI\")]\n",
    "        if ai_arms:\n",
    "            mean_ai_human = np.nanmean([jmat.loc[a, \"HUMAN\"] for a in ai_arms])\n",
    "\n",
    "    return {\n",
    "        \"Disease\": f\"{disease_code}_{disease_name}\",\n",
    "        \"N_AI\": sum(1 for a in arms if a.startswith(\"AI\")),\n",
    "        \"Mean_AI_Human_Jaccard\": mean_ai_human,\n",
    "        \"Mean_SetSize\": np.mean([len(s) for s in arm_data.values()]),\n",
    "        \"Mean_Jaccard_All\": np.nanmean(jmat.values)\n",
    "    }\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Run analysis\n",
    "# ----------------------------------------------------------\n",
    "all_summaries = []\n",
    "for disease_code, folders in sorted(disease_groups.items()):\n",
    "    res = analyze_disease(disease_code, TARGET_DISEASES[disease_code], folders)\n",
    "    if res:\n",
    "        all_summaries.append(res)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save combined summary\n",
    "# ----------------------------------------------------------\n",
    "summary_df = pd.DataFrame(all_summaries)\n",
    "summary_csv = os.path.join(OUT_DIR_PHASEA, \"phaseA_summary.csv\")\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "# print(\"\\nüìä Phase A summary saved ‚Üí\", summary_csv)\n",
    "# print(\"Columns:\", summary_df.columns.tolist())\n",
    "# print(\"Shape:\", summary_df.shape)\n",
    "# print(summary_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677a3be-6a4b-465c-b170-0a8dfbc258d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------\n",
    "# # 5Ô∏è‚É£ Summary Bar Chart: Union vs Intersection across all arms (AI + Human)\n",
    "# # ------------------------------\n",
    "# import pandas as pd\n",
    "\n",
    "# # print(\"\\nüìä Calculating union and intersection concept counts across all arms (AI + Human)...\\n\")\n",
    "\n",
    "# summary_records = []\n",
    "\n",
    "# for disease, arm_data in all_arm_data.items():\n",
    "#     # Compute union and intersection\n",
    "#     all_union = set().union(*arm_data.values())\n",
    "#     all_intersection = set.intersection(*arm_data.values())\n",
    "\n",
    "#     summary_records.append({\n",
    "#         \"Disease\": disease,\n",
    "#         \"Arm_Count\": len(arm_data),\n",
    "#         \"Union_Concepts\": len(all_union),\n",
    "#         \"Intersection_Concepts\": len(all_intersection)\n",
    "#     })\n",
    "\n",
    "# summary_df = pd.DataFrame(summary_records)\n",
    "# summary_df.to_csv(\"union_intersection_summary.csv\", index=False)\n",
    "\n",
    "# print(\"‚úÖ Saved 'union_intersection_summary.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec3558-3f5a-40d7-9b73-391496384014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Phase A ‚Äî AI vs Final Human (Direct Overlap Statistics)\n",
    "# ==========================================================\n",
    "\n",
    "\n",
    "OUT_DIR = os.path.join(SCRIPT_DIR, 'results', 'phaseA_AI_vs_Human')\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Compute AI vs Final Human overlap\n",
    "# ----------------------------------------------------------\n",
    "rows = []\n",
    "concept_summary_rows = []\n",
    "\n",
    "for disease_code, folders in sorted(disease_groups.items()):\n",
    "    ai_sets = []\n",
    "    human_set = set()\n",
    "\n",
    "    for f in folders:\n",
    "        fpath = os.path.join(ROOT_DIR, f, \"includedConcepts.csv\")\n",
    "        if not os.path.exists(fpath):\n",
    "            continue\n",
    "        if is_ai(f):\n",
    "            ai_sets.append(load_included_concepts(fpath))\n",
    "        elif is_final_human(f):\n",
    "            human_set = load_included_concepts(fpath)\n",
    "\n",
    "    if not ai_sets or not human_set:\n",
    "        print(f\"‚ö†Ô∏è Skipping {disease_code}_{TARGET_DISEASES[disease_code]}: Missing AI or Human data.\")\n",
    "        continue\n",
    "\n",
    "    ai_union = set().union(*ai_sets)\n",
    "    shared = ai_union & human_set\n",
    "    union_all = ai_union | human_set\n",
    "    jacc = jaccard_index(ai_union, human_set)\n",
    "\n",
    "    # print(f\"\\n=== Disease: {disease_code}_{TARGET_DISEASES[disease_code]} ===\")\n",
    "    # print(f\"AI_Total={len(ai_union)}, Human_Total={len(human_set)}, Shared={len(shared)}, Union={len(union_all)}, Jaccard={round(jacc,4)}\")\n",
    "\n",
    "    # Append summary row\n",
    "    rows.append({\n",
    "        \"Disease\": f\"{disease_code}_{TARGET_DISEASES[disease_code]}\",\n",
    "        \"AI_Total\": len(ai_union),\n",
    "        \"Human_Total\": len(human_set),\n",
    "        \"Shared\": len(shared),\n",
    "        \"Union\": len(union_all),\n",
    "        \"Jaccard\": round(jacc, 4)\n",
    "    })\n",
    "\n",
    "    # --- Per-arm breakdown ---\n",
    "    for f in folders:\n",
    "        fpath = os.path.join(ROOT_DIR, f, \"includedConcepts.csv\")\n",
    "        if not os.path.exists(fpath):\n",
    "            continue\n",
    "        if is_ai(f) or is_final_human(f):\n",
    "            arm = re.search(r\"\\[(AI\\d+|H\\d+)\\]\", f)\n",
    "            arm_name = arm.group(1).upper() if arm else f\n",
    "            if arm_name.startswith(\"H\"):\n",
    "                arm_name = \"HUMAN\"\n",
    "            sset = load_included_concepts(fpath)\n",
    "            other_sets = [\n",
    "                load_included_concepts(os.path.join(ROOT_DIR, other, \"includedConcepts.csv\"))\n",
    "                for other in folders if other != f and (is_ai(other) or is_final_human(other))\n",
    "                and os.path.exists(os.path.join(ROOT_DIR, other, \"includedConcepts.csv\"))\n",
    "            ]\n",
    "            others_union = set().union(*other_sets) if other_sets else set()\n",
    "            unique_to_arm = sset - others_union\n",
    "            concept_summary_rows.append({\n",
    "                \"Disease\": f\"{disease_code}_{TARGET_DISEASES[disease_code]}\",\n",
    "                \"Arm\": arm_name,\n",
    "                \"Concepts_Total\": len(sset),\n",
    "                \"Unique_to_Arm\": len(unique_to_arm),\n",
    "                \"Overlap_with_All\": len(sset & others_union)\n",
    "            })\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save outputs\n",
    "# ----------------------------------------------------------\n",
    "summary_df = pd.DataFrame(rows)\n",
    "concept_df = pd.DataFrame(concept_summary_rows)\n",
    "\n",
    "summary_csv = os.path.join(OUT_DIR, \"phaseA_AI_vs_Human.csv\")\n",
    "concept_csv = os.path.join(OUT_DIR, \"phaseA_concept_summary.csv\")\n",
    "\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "concept_df.to_csv(concept_csv, index=False)\n",
    "\n",
    "# print(\"\\nüìä Phase A summary saved ‚Üí\", summary_csv)\n",
    "# print(\"üìÑ Per-arm concept summary saved ‚Üí\", concept_csv)\n",
    "# print(\"Shape:\", summary_df.shape)\n",
    "# print(summary_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf24d4-cea8-4767-9d5c-94b30f5d5234",
   "metadata": {},
   "source": [
    "### Phase A ‚Äî Filtered AI‚ÄìHuman Overlap Metrics (FRD 6.1.4)\n",
    "- This cell extracts only the **core overlap statistics** from the combined Phase A summary for focused reporting and visualization.\n",
    "- It loads concept lists from all [AI#] and [H#] arms, computes Jaccard similarity, and reports total, shared, and unique concept counts, as well as per-arm breakdowns.\n",
    "- The selected columns include:  \n",
    "  - **Disease:** Identifier of the analyzed clinical condition.  \n",
    "  - **AI_Total / Human_Total:** Total number of included concepts per arm.  \n",
    "  - **Shared / Union:** Count of overlapping and total combined concepts.  \n",
    "  - **Jaccard:** Proportion of shared concepts relative to the union (AI‚ÄìHuman similarity).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131f206-d903-44ae-865a-76c300b3d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40db331-ef2d-4023-9ea1-897ab21bfec8",
   "metadata": {},
   "source": [
    "- This cell compiles per-arm concept statistics from all AI and Human workflows into a single structured table.  \n",
    "- It records, for each disease and arm, the **total concept count**, **unique concepts specific to that arm**, and **overlap with all other arms**.  \n",
    "- The resulting file **`concept_comparison_summary.csv`** (saved in `results/phaseA_AI_vs_Human/`) provides granular transparency on individual arm contributions and supports reproducibility of overlap metrics.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47152c-e6c6-45aa-8e20-83bd47097ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_df = pd.DataFrame(concept_summary_rows)\n",
    "out_concept = os.path.join(OUT_DIR, \"concept_comparison_summary.csv\")\n",
    "concept_df.to_csv(out_concept, index=False)\n",
    "# print(\"‚úÖ Saved:\", out_concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc0a4d-7509-4991-baee-552e1437fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8639fb7-60ab-401c-a34e-a8419f6fe11d",
   "metadata": {},
   "source": [
    "<!-- ### Phase A ‚Äî Visualization of Concept Counts and Overlaps (FRD 6.1.4)\n",
    "- This cell generates **bar chart visualizations** showing total, unique, and overlapping concept counts per arm (AI vs Human) for each disease.  \n",
    "- Using Seaborn and Matplotlib, it standardizes color-coded metrics:\n",
    "  - **Blue:** Total concepts per arm  \n",
    "  - **Green:** Concepts unique to that arm  \n",
    "  - **Red:** Overlap with all other arms  \n",
    "- The resulting charts (one per disease) visually summarize inter-arm differences in concept inclusion, supporting transparency and reproducibility in AI‚ÄìHuman comparison outcomes.  \n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9d182-a7f2-4804-8115-bfc25850a32f",
   "metadata": {},
   "source": [
    " <!-- \n",
    " **Phase A ‚Äî Visualization of Concept Counts and Overlaps (FRD 6.1.4)**\n",
    "\n",
    "    This cell generates bar chart visualizations showing total, unique, and overlapping concept counts per arm (AI vs Human) for each disease.\n",
    "    color-coded metrics:\n",
    "        Blue: Total concepts per arm\n",
    "        Green: Concepts unique to that arm\n",
    "        Red: Overlap with all other arms\n",
    "    The resulting charts (one per disease) visually summarize inter-arm differences in concept inclusion, supporting transparency and reproducibility in AI‚ÄìHuman comparison outcomes. \n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5bcf5-43dc-4329-a9dd-6aad6dd2d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================================================\n",
    "# # Visualization: Concept Counts and Overlaps per Arm\n",
    "# # ==========================================================\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# concept_summary = concept_df.copy()\n",
    "\n",
    "# # Set Seaborn theme\n",
    "# sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# # Define order and colors\n",
    "# arm_order = [\"HUMAN\", \"AI1\", \"AI2\", \"AI3\", \"AI4\"]\n",
    "# metric_palette = {\n",
    "#     \"Concepts_Total\": \"#4C72B0\",       # Blue - total concepts\n",
    "#     \"Unique_to_Arm\": \"#55A868\",        # Green - unique concepts\n",
    "#     \"Overlap_with_All\": \"#C44E52\"      # Red - overlap\n",
    "# }\n",
    "\n",
    "# # Generate per-disease bar charts\n",
    "# for disease in concept_summary[\"Disease\"].unique():\n",
    "#     sub = concept_summary[concept_summary[\"Disease\"] == disease].copy()\n",
    "\n",
    "#     # Keep consistent arm order\n",
    "#     sub[\"Arm\"] = pd.Categorical(\n",
    "#         sub[\"Arm\"],\n",
    "#         categories=[t for t in arm_order if t in sub[\"Arm\"].values] +\n",
    "#                    [t for t in sub[\"Arm\"].values if t not in arm_order],\n",
    "#         ordered=True\n",
    "#     )\n",
    "\n",
    "#     sub_melt = sub.melt(\n",
    "#         id_vars=[\"Arm\"],\n",
    "#         value_vars=[\"Concepts_Total\", \"Unique_to_Arm\", \"Overlap_with_All\"],\n",
    "#         var_name=\"Metric\", value_name=\"Count\"\n",
    "#     )\n",
    "\n",
    "#     plt.figure(figsize=(9, 5))\n",
    "#     ax = sns.barplot(\n",
    "#         data=sub_melt,\n",
    "#         x=\"Arm\", y=\"Count\", hue=\"Metric\",\n",
    "#         hue_order=[\"Concepts_Total\", \"Unique_to_Arm\", \"Overlap_with_All\"],\n",
    "#         order=sub[\"Arm\"].cat.categories,\n",
    "#         palette=metric_palette,\n",
    "#         edgecolor=\"black\", linewidth=0.6\n",
    "#     )\n",
    "\n",
    "#     for container in ax.containers:\n",
    "#         ax.bar_label(container, fmt='%d', label_type='edge', fontsize=9, padding=3)\n",
    "\n",
    "#     plt.title(f\"{disease}: Concept Counts and Overlaps per Arm\", fontsize=14, weight='bold', pad=15)\n",
    "#     plt.xlabel(\"Arm\", fontsize=12)\n",
    "#     plt.ylabel(\"Number of Concepts\", fontsize=12)\n",
    "#     plt.tick_params(axis='x', labelsize=12)\n",
    "#     plt.tick_params(axis='y', labelsize=12)\n",
    "#     plt.legend(\n",
    "#         title=\"Metric\", title_fontsize=11, fontsize=10,\n",
    "#         frameon=True, facecolor='white', edgecolor='gray'\n",
    "#     )\n",
    "\n",
    "#     plt.ylim(0, sub[\"Concepts_Total\"].max() * 1.3)\n",
    "#     sns.despine(left=True, bottom=True)\n",
    "#     plt.grid(axis='y', color='gray', linestyle='--', linewidth=0.4, alpha=0.6)\n",
    "#     plt.tight_layout()\n",
    "#     # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5b758-e761-4015-b6c1-a75b7bb3ae80",
   "metadata": {},
   "source": [
    "<!-- ### Phase A ‚Äî Pairwise & AI‚ÄìHuman Jaccard Analysis (FRD 6.1.3, 6.1.4)\n",
    "- This cell computes **pairwise Jaccard similarity** between all arms within each disease to quantify set overlap between subteams, AI, and final human arms.  \n",
    "- It also calculates **AI-vs-Human union, shared concepts, and Jaccard** for each disease, providing a direct pre-adjudication comparison.  \n",
    "- Output CSVs:\n",
    "  - `concept_armwise_metrics_summary.csv` ‚Üí pairwise Jaccard statistics for all arm combinations.  \n",
    "  - `concept_AI_vs_Human_metrics_summary.csv` ‚Üí AI vs final human summary metrics including total concepts, shared, union, and Jaccard.  \n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca037209-7efa-4bab-81f8-17a47301be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Phase A Extended ‚Äî Pairwise Jaccard Across All Arms\n",
    "# (Includes AI‚ÄìHuman overlap, AI‚ÄìAI, Human‚ÄìHuman, etc.)\n",
    "# ==========================================================\n",
    "\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------------------------\n",
    "# Analyze all diseases\n",
    "# --------------------------------------------\n",
    "pairwise_stats = []\n",
    "ai_vs_human_stats = []\n",
    "\n",
    "for disease_code, folders in sorted(disease_groups.items()):\n",
    "    disease_name = TARGET_DISEASES[disease_code]\n",
    "    arm_data = {}\n",
    "\n",
    "    for f in folders:\n",
    "        path = os.path.join(ROOT_DIR, f, \"includedConcepts.csv\")\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        arm_label = clean_arm_name(f)\n",
    "        arm_data[arm_label] = load_included_concepts(path)\n",
    "\n",
    "    if len(arm_data) < 2:\n",
    "        print(f\"‚ö†Ô∏è Skipping {disease_code}_{disease_name}: not enough arms.\")\n",
    "        continue\n",
    "\n",
    "    # --------------------------\n",
    "    # Pairwise Jaccard similarity\n",
    "    # --------------------------\n",
    "    for (arm1, set1), (arm2, set2) in combinations(arm_data.items(), 2):\n",
    "        inter = len(set1 & set2)\n",
    "        union = len(set1 | set2)\n",
    "        jaccard = inter / union if union else 0\n",
    "        pairwise_stats.append({\n",
    "            \"Disease\": f\"{disease_code}_{disease_name}\",\n",
    "            \"Arm1\": arm1,\n",
    "            \"Arm2\": arm2,\n",
    "            \"Shared\": inter,\n",
    "            \"Union\": union,\n",
    "            \"Jaccard\": round(jaccard, 4)\n",
    "        })\n",
    "\n",
    "    # --------------------------\n",
    "    # AI vs Human summary\n",
    "    # --------------------------\n",
    "    ai_arms = [concepts for arm, concepts in arm_data.items() if arm.startswith(\"AI\")]\n",
    "    human_arms = [concepts for arm, concepts in arm_data.items() if arm == \"HUMAN\"]\n",
    "\n",
    "    if ai_arms and human_arms:\n",
    "        ai_union = set().union(*ai_arms)\n",
    "        human_union = set().union(*human_arms)\n",
    "        shared = len(ai_union & human_union)\n",
    "        union_all = len(ai_union | human_union)\n",
    "        jaccard = shared / union_all if union_all else 0\n",
    "        ai_vs_human_stats.append({\n",
    "            \"Disease\": f\"{disease_code}_{disease_name}\",\n",
    "            \"AI_Total\": len(ai_union),\n",
    "            \"Human_Total\": len(human_union),\n",
    "            \"Shared\": shared,\n",
    "            \"Union\": union_all,\n",
    "            \"Jaccard\": round(jaccard, 4)\n",
    "        })\n",
    "\n",
    "# --------------------------------------------\n",
    "# Save results\n",
    "# --------------------------------------------\n",
    "pairwise_df = pd.DataFrame(pairwise_stats)\n",
    "ai_vs_human_df = pd.DataFrame(ai_vs_human_stats)\n",
    "\n",
    "pairwise_csv = os.path.join(OUT_DIR, \"concept_armwise_metrics_summary.csv\")\n",
    "aih_csv = os.path.join(OUT_DIR, \"concept_AI_vs_Human_metrics_summary.csv\")\n",
    "\n",
    "pairwise_df.to_csv(pairwise_csv, index=False)\n",
    "ai_vs_human_df.to_csv(aih_csv, index=False)\n",
    "\n",
    "# print(\"\\n‚úÖ Results generated successfully.\")\n",
    "# print(f\"Pairwise comparisons: {len(pairwise_df)} ‚Üí {pairwise_csv}\")\n",
    "# print(f\"AI vs Human summaries: {len(ai_vs_human_df)} ‚Üí {aih_csv}\")\n",
    "# print(ai_vs_human_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c780d-383a-401d-9626-2d459d0af497",
   "metadata": {},
   "source": [
    "### Phase A ‚Äî Pairwise Jaccard Similarity Heatmaps\n",
    "\n",
    "- **Purpose:** Visualize pairwise overlap (Jaccard similarity) between all arms for each disease.\n",
    "- **Inputs:** `pairwise_df` containing all Arm1‚ÄìArm2 Jaccard values per disease.\n",
    "- **Process:**\n",
    "  1. Identify all arms in the disease.\n",
    "  2. Build a square matrix of Jaccard values (diagonal = 1.0).\n",
    "  3. Fill the matrix using pairwise Jaccard data.\n",
    "  4. Plot a heatmap using Seaborn (`Blues` colormap, 0‚Äì1 scale).\n",
    "- **Visualization Notes:**\n",
    "  - Darker blue indicates higher overlap.\n",
    "  - Numeric values annotated on the heatmap.\n",
    "- **Outcome:** Quick visual inspection of agreement or divergence among AI, human, and subteam arms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f0b2c-1f24-464d-96aa-cacb4144c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Pairwise Jaccard Similarity Heatmaps\n",
    "# ------------------------------\n",
    "# For each disease, create a heatmap showing Jaccard similarity\n",
    "# between all pairs of arms.\n",
    "\n",
    "print(\"üìä Pairwise Jaccard Similarity Heatmaps: Shows Jaccard similarity (0‚Äì1) between all pairs of arms for each disease. Darker blue = higher overlap.\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure seaborn style is consistent\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "for disease in pairwise_df['Disease'].unique():\n",
    "    # Subset data for current disease\n",
    "    sub = pairwise_df[pairwise_df['Disease'] == disease]\n",
    "\n",
    "    # Identify all arms involved\n",
    "    arms = sorted(list(set(sub['Arm1']) | set(sub['Arm2'])))\n",
    "\n",
    "    # Initialize square matrix with 1.0 on the diagonal\n",
    "    matrix = pd.DataFrame(1.0, index=arms, columns=arms)\n",
    "\n",
    "    # Fill in Jaccard values\n",
    "    for _, row in sub.iterrows():\n",
    "        matrix.loc[row['Arm1'], row['Arm2']] = row['Jaccard']\n",
    "        matrix.loc[row['Arm2'], row['Arm1']] = row['Jaccard']\n",
    "\n",
    "    # ------------------------------\n",
    "    # Plot heatmap\n",
    "    # ------------------------------\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        matrix,\n",
    "        annot=True,\n",
    "        annot_kws={\"size\": 11},  # smaller font for numbers\n",
    "        cmap=\"Blues\",\n",
    "        vmin=0,\n",
    "        vmax=1\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Pairwise Jaccard Similarity ‚Äî {disease}\", fontsize=10)\n",
    "    plt.xticks(fontsize=10, rotation=45, ha='right')\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ba78a-040c-4ea9-9079-5f5c0d43e9e8",
   "metadata": {},
   "source": [
    "<!-- ### Phase A ‚Äî Upset Plot Visualization of Concept Intersections (FRD 6.1.4‚Äì6.1.5)\n",
    "- This cell generates **Upset plots** to visualize intersections between concept sets across all AI and Human workflows for each disease.  \n",
    "- Each plot shows how concepts are shared or unique among workflows, highlighting methodological overlap and outliers before gold standard adjudication.  \n",
    "- The outputs, saved under `results/phaseA_AI_vs_Human/upset_plots/`, are per-disease PNG files (e.g., `C01_upset_plot.png`) that provide an intuitive view of workflow intersections and uniqueness.  \n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba062f-e310-49b3-acda-c8893bf79956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================================================\n",
    "# # Upset Plot ‚Äî Concept Set Intersections Across Workflows\n",
    "# # ==========================================================\n",
    "# print(\"\\nüìä Generating Upset plots (concept intersections across workflows)...\\n\")\n",
    "\n",
    "# from upsetplot import UpSet, from_memberships\n",
    "\n",
    "# UPSET_DIR = os.path.join(OUT_DIR, \"upset_plots\")\n",
    "# os.makedirs(UPSET_DIR, exist_ok=True)\n",
    "\n",
    "# for disease in concept_df[\"Disease\"].unique():\n",
    "#     disease_dir = os.path.join(ROOT_DIR, disease)\n",
    "#     wf_sets = {}\n",
    "\n",
    "#     # Load all AI + HUMAN sets\n",
    "#     for sub in os.listdir(disease_dir):\n",
    "#         subpath = os.path.join(disease_dir, sub, \"includedConcepts.csv\")\n",
    "#         if not os.path.exists(subpath):\n",
    "#             continue\n",
    "#         if is_ai(sub) or is_final_human(sub):\n",
    "#             arm = re.search(r\"\\[(AI\\d+|H\\d+)\\]\", sub)\n",
    "#             arm_name = arm.group(1).upper() if arm else sub\n",
    "#             if arm_name.startswith(\"H\"):\n",
    "#                 arm_name = \"HUMAN\"\n",
    "#             wf_sets[arm_name] = load_included_concepts(subpath)\n",
    "\n",
    "#     if not wf_sets:\n",
    "#         continue\n",
    "\n",
    "#     # Build membership list for upset plot\n",
    "#     wf_cols = list(wf_sets.keys())\n",
    "#     all_concepts = sorted(set().union(*wf_sets.values()))\n",
    "#     memberships = [tuple(np.array(wf_cols)[[cid in wf_sets[w] for w in wf_cols]])\n",
    "#                    for cid in all_concepts]\n",
    "\n",
    "#     data = from_memberships(memberships)\n",
    "#     fig = plt.figure(figsize=(9, 5))\n",
    "#     UpSet(data, show_counts=True, subset_size='count').plot(fig=fig)\n",
    "#     plt.suptitle(f\"{disease}: Concept Set Intersections\", fontsize=13, weight='bold', y=1.02)\n",
    "#     fig.subplots_adjust(top=0.9, bottom=0.18, left=0.18, right=0.95)\n",
    "#     out_path = os.path.join(UPSET_DIR, f\"{disease}_upset_plot.png\")\n",
    "#     plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "#     # plt.show()\n",
    "\n",
    "#     # print(f\"‚úÖ Saved Upset plot for {disease} ‚Üí {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151db2d-7bc9-4020-9224-18c4b035ed99",
   "metadata": {},
   "source": [
    "<!-- ### Phase A ‚Äî Concept Agreement & Clinical Context Visualizations (FRD 6.1.5)\n",
    "- This cell analyzes **how consistently concepts are selected across AI and Human workflows** by computing a Match Score for each concept (number of workflows including it).  \n",
    "- Two visualizations are generated per disease:  \n",
    "  1. **Histogram of Match Scores** ‚Äî shows distribution of agreement levels across workflows.  \n",
    "  2. **Scatter Plot (Match Score vs Concept Prevalence)** ‚Äî highlights clinically significant discrepancies (high prevalence concepts with low agreement).  \n",
    "- Outputs are saved in `results/phaseA_AI_vs_Human/concept_agreement/` as PNG files, providing insight into workflow consistency and clinical relevance before gold standard adjudication.  \n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001782ef-1768-4743-8092-b79ff571b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================================================\n",
    "# # Concept Agreement and Clinical Context Analysis (Refined)\n",
    "# # ==========================================================\n",
    "# print(\"\\nüìä Generating Concept Agreement & Clinical Context visualizations...\\n\")\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ----------------------------------------------------------\n",
    "# # Setup\n",
    "# # ----------------------------------------------------------\n",
    "# AGREEMENT_DIR = os.path.join(OUT_DIR, \"concept_agreement\")\n",
    "# os.makedirs(AGREEMENT_DIR, exist_ok=True)\n",
    "\n",
    "# # ----------------------------------------------------------\n",
    "# # Load record counts (for prevalence axis)\n",
    "# # ----------------------------------------------------------\n",
    "# record_map = {}\n",
    "# record_count_file = os.path.join(ROOT_DIR, \"ConceptRecordCounts.csv\")\n",
    "\n",
    "# if os.path.exists(record_count_file):\n",
    "#     rc = pd.read_csv(record_count_file, dtype=str)\n",
    "#     rc['conceptId'] = rc['conceptId'].astype(str).str.strip().str.replace(r'\\.0+$', '', regex=True)\n",
    "#     rc['record_count'] = pd.to_numeric(rc['record_count'], errors='coerce').fillna(0.0)\n",
    "#     record_map = dict(zip(rc['conceptId'], rc['record_count']))\n",
    "#     print(f\"‚úÖ Loaded {len(record_map):,} concept record counts for prevalence mapping.\")\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è ConceptRecordCounts.csv not found ‚Äî skipping prevalence axis.\")\n",
    "\n",
    "# # ----------------------------------------------------------\n",
    "# # Loop through diseases\n",
    "# # ----------------------------------------------------------\n",
    "# for disease in concept_df[\"Disease\"].unique():\n",
    "#     disease_dir = os.path.join(ROOT_DIR, disease)\n",
    "#     wf_sets = {}\n",
    "\n",
    "#     # Collect concept sets for AI and Human workflows\n",
    "#     for sub in os.listdir(disease_dir):\n",
    "#         subpath = os.path.join(disease_dir, sub, \"includedConcepts.csv\")\n",
    "#         if not os.path.exists(subpath):\n",
    "#             continue\n",
    "#         if is_ai(sub) or is_final_human(sub):\n",
    "#             arm = re.search(r\"\\[(AI\\d+|H\\d+)\\]\", sub)\n",
    "#             arm_name = arm.group(1).upper() if arm else sub\n",
    "#             if arm_name.startswith(\"H\"):\n",
    "#                 arm_name = \"HUMAN\"\n",
    "#             wf_sets[arm_name] = load_included_concepts(subpath)\n",
    "\n",
    "#     if not wf_sets:\n",
    "#         continue\n",
    "\n",
    "#     # ------------------------------------------------------\n",
    "#     # Compute Match Score (agreement level)\n",
    "#     # ------------------------------------------------------\n",
    "#     all_concepts = sorted(set().union(*wf_sets.values()))\n",
    "#     match_score = {cid: sum(1 for s in wf_sets.values() if cid in s) for cid in all_concepts}\n",
    "\n",
    "#     df = pd.DataFrame({\n",
    "#         \"conceptId\": all_concepts,\n",
    "#         \"MatchScore\": [match_score[cid] for cid in all_concepts],\n",
    "#         \"record_count\": [\n",
    "#             record_map.get(str(cid).strip().replace(\".0\", \"\"), np.nan)\n",
    "#             for cid in all_concepts\n",
    "#         ]\n",
    "#     })\n",
    "\n",
    "#     # ------------------------------------------------------\n",
    "#     # Histogram of Match Scores (Agreement distribution)\n",
    "#     # ------------------------------------------------------\n",
    "#     plt.figure(figsize=(5.5, 3.8))\n",
    "#     plt.hist(df[\"MatchScore\"], bins=range(1, len(wf_sets) + 2), edgecolor=\"black\", color=\"#4C72B0\")\n",
    "#     plt.xlabel(\"Match Score (# of Workflows)\", fontsize=11)\n",
    "#     plt.ylabel(\"Number of Concepts\", fontsize=11)\n",
    "#     plt.title(f\"{disease}: Match Score Distribution\", fontsize=12, weight=\"bold\", pad=8)\n",
    "#     plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "#     plt.tight_layout()\n",
    "#     hist_path = os.path.join(AGREEMENT_DIR, f\"{disease}_matchscore_histogram.png\")\n",
    "#     plt.savefig(hist_path, dpi=300, bbox_inches=\"tight\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # ------------------------------------------------------\n",
    "#     # Scatter: Match Score vs Concept Prevalence\n",
    "#     # ------------------------------------------------------\n",
    "#     if record_map:\n",
    "#         plt.figure(figsize=(6.2, 4.5))\n",
    "#         plt.scatter(\n",
    "#             df[\"record_count\"], df[\"MatchScore\"],\n",
    "#             alpha=0.6, s=35, edgecolor='k', linewidth=0.4, color=\"#55A868\"\n",
    "#         )\n",
    "#         plt.xscale(\"log\")\n",
    "#         plt.xlabel(\"Concept Prevalence (Record Count, log scale)\", fontsize=11)\n",
    "#         plt.ylabel(\"Match Score (# Workflows including concept)\", fontsize=11)\n",
    "#         plt.title(f\"{disease}: Agreement vs Clinical Prevalence\", fontsize=12, weight=\"bold\", pad=8)\n",
    "#         plt.grid(alpha=0.4, linestyle='--')\n",
    "#         plt.tight_layout()\n",
    "#         scatter_path = os.path.join(AGREEMENT_DIR, f\"{disease}_agreement_vs_prevalence.png\")\n",
    "#         plt.savefig(scatter_path, dpi=300, bbox_inches=\"tight\")\n",
    "#         plt.show()\n",
    "\n",
    "# # print(\"\\n‚úÖ Concept Agreement & Clinical Context visualizations generated in:\", AGREEMENT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e6948-7180-4269-803b-fa9f3ba6067a",
   "metadata": {},
   "source": [
    "<!-- ### Phase A ‚Äî AI Arms Union vs Intersection Summary (FRD 6.1.4‚Äì6.1.5)\n",
    "- This cell calculates the **union and intersection** of concept sets across all AI arms for each disease to quantify agreement and variability among AI workflows.  \n",
    "- The results are saved in `AI_arms_union_intersection_summary.csv`, containing per-disease counts for total concepts (union) and shared concepts (intersection).  \n",
    "- A bar chart visualizes these metrics, comparing **agreement vs diversity** across AI arms and highlighting areas of high or low overlap before adjudication.  \n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356616ab-9fb1-42b3-a7d4-66a8341a0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------\n",
    "# # 5Ô∏è‚É£ Summary Bar Chart: Union vs Intersection across AI arms\n",
    "# # ------------------------------\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# from itertools import combinations\n",
    "\n",
    "# print(\"\\nüìä Calculating union and intersection concept counts across AI arms...\\n\")\n",
    "\n",
    "# summary_ai = []\n",
    "\n",
    "# for disease, arm_data in all_arm_data.items():\n",
    "#     # Filter only AI arms\n",
    "#     ai_arms = {arm: concepts for arm, concepts in arm_data.items() if arm.lower().startswith(\"ai\")}\n",
    "#     if len(ai_arms) < 2:\n",
    "#         continue  # skip if less than 2 AI arms\n",
    "\n",
    "#     # Compute union and intersection\n",
    "#     union_set = set().union(*ai_arms.values())\n",
    "#     intersection_set = set.intersection(*ai_arms.values()) if len(ai_arms) > 1 else set()\n",
    "\n",
    "#     summary_ai.append({\n",
    "#         \"Disease\": disease,\n",
    "#         \"AI_Arm_Count\": len(ai_arms),\n",
    "#         \"Union_Concepts\": len(union_set),\n",
    "#         \"Intersection_Concepts\": len(intersection_set)\n",
    "#     })\n",
    "\n",
    "# summary_df = pd.DataFrame(summary_ai)\n",
    "# summary_df.to_csv(\"AI_arms_union_intersection_summary.csv\", index=False)\n",
    "\n",
    "# #print(\"‚úÖ Saved 'AI_arms_union_intersection_summary.csv'\")\n",
    "\n",
    "\n",
    "# # ------------------------------\n",
    "# # Visualization\n",
    "# # ------------------------------\n",
    "# sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# summary_melted = summary_df.melt(id_vars=\"Disease\",\n",
    "#                                  value_vars=[\"Union_Concepts\", \"Intersection_Concepts\"],\n",
    "#                                  var_name=\"Metric\",\n",
    "#                                  value_name=\"Count\")\n",
    "\n",
    "# sns.barplot(data=summary_melted, x=\"Disease\", y=\"Count\", hue=\"Metric\")\n",
    "# plt.title(\"Union vs Intersection of Concept IDs across AI Arms per Disease\")\n",
    "# plt.xlabel(\"Disease\")\n",
    "# plt.ylabel(\"Number of Concept IDs\")\n",
    "# plt.xticks(rotation=45, ha=\"right\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5500258-5ace-48b1-8abc-fdedecb4ade8",
   "metadata": {},
   "source": [
    "### Phase A ‚Äî AI Arms Union vs Intersection Bar Chart (FRD 6.1.4‚Äì6.1.5)\n",
    "- This cell calculates the **union and intersection of concept sets** across all AI arms for each disease, highlighting agreement and variability among AI pipelines.  \n",
    "- The results are saved in **`AI_arms_union_intersection_summary.csv`**, containing per-disease counts for:\n",
    "  - **AI_Arm_Count:** Number of AI arms included.  \n",
    "  - **Union_Concepts:** Total unique concepts across AI arms.  \n",
    "  - **Intersection_Concepts:** Concepts shared by all AI arms.  \n",
    "- A bar chart visualizes these metrics, comparing total vs shared concepts per disease to easily identify where AI outputs converge or diverge.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d463b0-4f6d-40bc-8d1f-0d683273f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Phase A ‚Äî Union vs Intersection Summary (AI + Human Arms)\n",
    "# ==========================================================\n",
    "import os, re, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "OUT_DIR = os.path.join(SCRIPT_DIR, 'results', 'phaseA_union_intersection')\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Compute union vs intersection\n",
    "# --------------------------------------------\n",
    "summary_records = []\n",
    "\n",
    "for disease_code, folders in sorted(disease_groups.items()):\n",
    "    disease_name = TARGET_DISEASES[disease_code]\n",
    "    arm_data = {}\n",
    "\n",
    "    for f in folders:\n",
    "        fpath = os.path.join(ROOT_DIR, f, \"includedConcepts.csv\")\n",
    "        if not os.path.exists(fpath):\n",
    "            continue\n",
    "        if is_ai(f) or is_final_human(f):\n",
    "            arm_data[clean_arm_name(f)] = load_included_concepts(fpath)\n",
    "\n",
    "    if not arm_data:\n",
    "        print(f\"‚ö†Ô∏è Skipping {disease_code}_{disease_name}: no valid arms found.\")\n",
    "        continue\n",
    "\n",
    "    all_union = set().union(*arm_data.values())\n",
    "    all_intersection = set.intersection(*arm_data.values()) if len(arm_data) > 1 else set()\n",
    "\n",
    "    summary_records.append({\n",
    "        \"Disease\": f\"{disease_code}_{disease_name}\",\n",
    "        \"Arm_Count\": len(arm_data),\n",
    "        \"Union_Concepts\": len(all_union),\n",
    "        \"Intersection_Concepts\": len(all_intersection),\n",
    "        \"Intersection_to_Union_Ratio\": round(len(all_intersection) / len(all_union), 4) if all_union else 0.0\n",
    "    })\n",
    "\n",
    "# --------------------------------------------\n",
    "# Save summary table\n",
    "# --------------------------------------------\n",
    "summary_df = pd.DataFrame(summary_records)\n",
    "out_csv = os.path.join(OUT_DIR, \"union_intersection_summary.csv\")\n",
    "summary_df.to_csv(out_csv, index=False)\n",
    "\n",
    "# print(\"\\n‚úÖ Saved union/intersection summary ‚Üí\", out_csv)\n",
    "# print(\"Columns:\", summary_df.columns.tolist())\n",
    "# print(\"Shape:\", summary_df.shape)\n",
    "# print(summary_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be120fbf-9872-471c-ae9a-20682524b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5dccc1-0ab2-4410-b2a5-522dfaa29a08",
   "metadata": {},
   "source": [
    "### Phase A ‚Äî Horizontal Stacked Bars: AI Union vs Intersection (FRD 6.1.4)\n",
    "- This cell visualizes the **distribution of AI-generated concepts** across diseases, comparing the total union of AI concepts with the intersection shared with the Human workflow.  \n",
    "- Two plots are generated per disease:  \n",
    "  1. **Percentage stacked bars:** normalized view showing proportion of AI-only vs shared concepts.  \n",
    "  2. **Absolute numbers stacked bars:** actual counts of concepts in AI-only and shared categories.  \n",
    "- These plots help **quickly identify agreement vs divergence** between AI outputs and Human references prior to adjudication.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2cc03-bf2d-4354-84f9-98ae41523839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 6Ô∏è‚É£ Horizontal Stacked Bars: Union vs Intersection of AI Concepts\n",
    "# ------------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Prepare data\n",
    "# ---------------------------------------------\n",
    "stack_df = summary_df.copy()\n",
    "stack_df = stack_df.sort_values(by=\"Union_Concepts\", ascending=True)  # smallest to largest for readability\n",
    "\n",
    "# Compute AI-only and intersection\n",
    "stack_df[\"AI_Only\"] = stack_df[\"Union_Concepts\"] - stack_df[\"Intersection_Concepts\"]\n",
    "stack_df[\"In_Both\"] = stack_df[\"Intersection_Concepts\"]\n",
    "\n",
    "# Compute percentages for normalized plot\n",
    "stack_df[\"AI_Only_%\"] = stack_df[\"AI_Only\"] / stack_df[\"Union_Concepts\"] * 100\n",
    "stack_df[\"In_Both_%\"] = stack_df[\"In_Both\"] / stack_df[\"Union_Concepts\"] * 100\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Plot 1Ô∏è‚É£: Percentages\n",
    "# ---------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_df_pct = stack_df.set_index(\"Disease\")[[\"In_Both_%\", \"AI_Only_%\"]]\n",
    "\n",
    "plot_df_pct.plot(\n",
    "    kind=\"barh\",\n",
    "    stacked=True,\n",
    "    color=[\"#A6CEE3\", \"#FDBF6F\"],  # blue & amber\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.6\n",
    ")\n",
    "\n",
    "plt.title(\"AI Concept Distribution Across Diseases (Percentage)\", fontsize=15, weight=\"bold\")\n",
    "plt.xlabel(\"Percentage of Concepts\", fontsize=13)\n",
    "plt.ylabel(\"Disease\", fontsize=13)\n",
    "plt.legend(\n",
    "    [\"In Both (Intersection)\", \"AI Only (Union ‚àí Intersection)\"],\n",
    "    title=\"Category\",\n",
    "    title_fontsize=12,\n",
    "    fontsize=11,\n",
    "    bbox_to_anchor=(1.04, 0.5),\n",
    "    loc=\"center left\",\n",
    "    frameon=False\n",
    ")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Plot 2Ô∏è‚É£: Absolute Numbers\n",
    "# ---------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_df_abs = stack_df.set_index(\"Disease\")[[\"In_Both\", \"AI_Only\"]]\n",
    "\n",
    "plot_df_abs.plot(\n",
    "    kind=\"barh\",\n",
    "    stacked=True,\n",
    "    color=[\"#A6CEE3\", \"#FDBF6F\"],  # same palette\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.6\n",
    ")\n",
    "\n",
    "plt.title(\"Concept Distribution Across Diseases (Absolute Numbers)\", fontsize=15, weight=\"bold\")\n",
    "plt.xlabel(\"Number of Concept IDs\", fontsize=13)\n",
    "plt.ylabel(\"Disease\", fontsize=13)\n",
    "plt.legend(\n",
    "    [\"In Both (Intersection)\", \"AI Only (Union ‚àí Intersection)\"],\n",
    "    title=\"Category\",\n",
    "    title_fontsize=12,\n",
    "    fontsize=11,\n",
    "    bbox_to_anchor=(1.04, 0.5),\n",
    "    loc=\"center left\",\n",
    "    frameon=False\n",
    ")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6071915-83aa-4cc7-9335-645d77b08c7a",
   "metadata": {},
   "source": [
    "### Phase A ‚Äî Horizontal Stacked Bar: AI vs Human Concept Overlap (FRD 6.1.4‚Äì6.1.5)\n",
    "- This cell generates a **stacked horizontal bar chart** showing concept overlap across diseases for AI and Human workflows.  \n",
    "- Each bar is divided into **In Both (shared concepts), All AI, and Human Only**, both as percentages of the total union.  \n",
    "- The visualization allows quick assessment of **agreement, divergence, and unique contributions** of AI and Human arms prior to adjudication.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4826dd-e84e-4889-ac0c-f2a428af1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------------\n",
    "df_path = os.path.join(\"results\", \"phaseA_AI_vs_Human\", \"phaseA_AI_vs_Human.csv\")\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Compute overlap components\n",
    "# ---------------------------------------------\n",
    "df[\"AI_Only\"] = df[\"AI_Total\"] - df[\"Shared\"]\n",
    "df[\"Human_Only\"] = df[\"Human_Total\"] - df[\"Shared\"]\n",
    "df[\"In_Both\"] = df[\"Shared\"]\n",
    "\n",
    "# Normalize by union (ensure union is correct)\n",
    "df[\"Union\"] = df[\"AI_Only\"] + df[\"Human_Only\"] + df[\"In_Both\"]\n",
    "\n",
    "df[\"AI_Only_%\"] = df[\"AI_Only\"] / df[\"Union\"] * 100\n",
    "df[\"Human_Only_%\"] = df[\"Human_Only\"] / df[\"Union\"] * 100\n",
    "df[\"In_Both_%\"] = df[\"In_Both\"] / df[\"Union\"] * 100\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Prepare for plotting\n",
    "# ---------------------------------------------\n",
    "plot_df = df.set_index(\"Disease\")[[\"In_Both_%\", \"AI_Only_%\", \"Human_Only_%\"]]\n",
    "\n",
    "# Sort by shared overlap for better comparison\n",
    "plot_df = plot_df.sort_values(\"In_Both_%\", ascending=True)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Plot: Horizontal stacked bar\n",
    "# ---------------------------------------------\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plot_df.plot(\n",
    "    kind=\"barh\",\n",
    "    stacked=True,\n",
    "    color=[\"#A6CEE3\", \"#FB9A99\", \"#B2DF8A\"],  # Blue, Red, Green\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.6,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    \"Phase 1: Concept Overlap Between AI and Human Workflows\",\n",
    "    fontsize=14,\n",
    "    weight=\"bold\"\n",
    ")\n",
    "ax.set_xlabel(\"Percentage of Concepts\", fontsize=13)\n",
    "ax.set_ylabel(\"Concept Sets\", fontsize=13)\n",
    "\n",
    "# Legend with correct order and labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(\n",
    "    handles,\n",
    "    [\"In Both\", \"AI Only\", \"Human Only\"],\n",
    "    title=\"Category\",\n",
    "    title_fontsize=12,\n",
    "    fontsize=11,\n",
    "    bbox_to_anchor=(1.04, 0.5),\n",
    "    loc=\"center left\",\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# Clean gridlines and layout\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4efcf6-4af7-42c0-8eee-a85020ef2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html --no-input --output \"Phase1_results.html\" \"Phase1.ipynb\" --log-level=ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8e8e9-d909-4009-b5c7-b2806ef862cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
